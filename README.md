# Nigerian Sign Language (NSL) Recognition with YOLOv8 and ESP32-CAM

This project recognizes **Nigerian Sign Language (NSL)** hand gestures using an **ESP32-CAM** for data collection and a **YOLOv8** model for training/inference.  
A **Flask web app** serves real-time predictions from the trained model.

ğŸ”— **Main Repository:** https://github.com/centbueze/nigeria-signs-language

---

## ğŸ“Œ Project Overview
- ğŸ“· **Data Collection:** Images captured with **ESP32-CAM** (programmed via **Arduino IDE**).
- ğŸ“ **Annotation:** Labeled with LabelImg/Roboflow in **YOLO format**.
- ğŸ¤– **Model Training:** Trained a **YOLOv8** model producing `best.pt`.
- ğŸŒ **Deployment:** **Flask** API for real-time hand gesture recognition.
- ğŸ¯ **Goal:** Practical NSL recognition to support accessibility & inclusion.

---

## ğŸ“‚ Repository Structure
nigeria-signs-language/

â”‚â”€â”€ app.py # Flask server (inference)
â”‚â”€â”€ requirements.txt # Python dependencies

â”‚â”€â”€ README.md

â”‚â”€â”€ .gitignore

â”‚â”€â”€ dataset/ # Optional: sample or link to dataset
â”‚ â”œâ”€â”€ train/images/ train/labels/
â”‚ â””â”€â”€ val/images/ val/labels/

â”‚â”€â”€ output/
â”‚ â””â”€â”€ nsl_yolo_train2/
â”‚ â””â”€â”€ weights/
â”‚ â””â”€â”€ best.pt # Trained YOLOv8 weights (provide or link)

â”‚â”€â”€ templates/ # Flask HTML (if UI is used)

â”‚â”€â”€ static/ # CSS/JS/assets (if UI is used)

â”‚â”€â”€ esp32_cam/ # Arduino sketches & notes (data collection)

---

## ğŸ“œ requirements.txt (minimal)
flask

ultralytics

opencv-python

numpy

torch

torchvision

---

## ğŸ§  Model Path (important)
from ultralytics import YOLO

model_path = r"output/nsl_yolo_train2/weights/best.pt"

model = YOLO(model_path)

---

## ğŸ§ª Quick Inference (CLI)
yolo predict model=output/nsl_yolo_train2/weights/best.pt source=0
# or
yolo predict model=output/nsl_yolo_train2/weights/best.pt source="sample.jpg"

---

## ğŸ¯ Training
yolo detect train data=dataset/data.yaml model=yolov8n.pt epochs=50 imgsz=640


---

## ğŸ“„Dataset/data.yaml
path: ./dataset

train: train/images

val: val/images

nc: 26

names: [A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z]

---

## ğŸ“Š Dataset Structure
dataset/

â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/

â””â”€â”€ val/
    â”œâ”€â”€ images/
    â””â”€â”€ labels/

---

## ğŸ“² ESP32-CAM Data Collection (Arduino)
Install Arduino IDE + ESP32 board support (Boards Manager â†’ â€œesp32â€).

Flash CameraWebServer or custom sketch in esp32_cam/.

Select ESP32-CAM board + correct COM port â†’ Upload.

Open Serial Monitor â†’ copy ESP32 IP address.

Visit http://<ESP32_IP>/ â†’ live stream.

Capture gesture frames â†’ save into dataset folders â†’ label later.

---

## ğŸ–¼ï¸ Demo
![V_1752583739738](https://github.com/user-attachments/assets/5f7764e0-c27a-47da-9a99-0c91cd4e429b)

---

## ğŸ”§ .gitignore
flaskenv/

venv/

__pycache__/

*.pyc
*.pkl
*.onnx
*.h5
*.pth
*.dll
*.so
*.lib
runs/

---

## ğŸ§© Troubleshooting
pip install -r requirements.txt

---

## ğŸ™ Acknowledgements
Ultralytics YOLOv8
ESP32-CAM + Arduino IDE
Nigerian Sign Language Community
GitHub LFS (Large Files) for handling .pt models

---

## ğŸ§ğŸ Linux / Mac
```bash
python3 -m venv flaskenv
source flaskenv/bin/activate
```

---

## ğŸš€ Run the Flask App
python app.py

---

## ğŸŒ Open in your browser
[Ultralytics YOLOv8
ESP32-CAM + Arduino IDE
Nigerian Sign Language Community
GitHub LFS (Large Files) for handling .pt models](http://127.0.0.1:5000/)

---

